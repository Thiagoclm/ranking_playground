{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thiagoclm/Library/Python/3.9/lib/python/site-packages/urllib3/__init__.py:34: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/thiagoclm/Library/Python/3.9/lib/python/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import ndcg_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from datasets import load_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import load_dataset\n",
    "\n",
    "def prepare_datasets():\n",
    "    \"\"\"\n",
    "    Load MSLR-WEB10K dataset using Hugging Face's `datasets` library.\n",
    "    Returns:\n",
    "        X_train, y_train, X_valid, y_valid, X_test, y_test\n",
    "    \"\"\"\n",
    "    ds = load_dataset(\"philipphager/MSLR-WEB10k\")\n",
    "\n",
    "    def process_split(split):\n",
    "        \"\"\"\n",
    "        Processes a dataset split to extract features and labels.\n",
    "        Args:\n",
    "            split (Dataset): A split of the dataset (train, validation, test).\n",
    "        Returns:\n",
    "            X (ndarray): Feature matrix.\n",
    "            y (ndarray): Relevance scores.\n",
    "        \"\"\"\n",
    "        features = split[\"features\"]\n",
    "        relevance = np.array(split[\"relevance_label\"])\n",
    "\n",
    "        # Check the shape of each element in features\n",
    "        feature_shapes = [np.shape(f) for f in features]\n",
    "        print(\"Feature shapes:\", feature_shapes)\n",
    "\n",
    "        # Convert features to a NumPy array\n",
    "        features = np.array([np.array(f) for f in features])\n",
    "\n",
    "        return features, relevance\n",
    "\n",
    "    X_train, y_train = process_split(ds[\"train\"])\n",
    "    X_valid, y_valid = process_split(ds[\"validation\"])\n",
    "    X_test, y_test = process_split(ds[\"test\"])\n",
    "    return X_train, y_train, X_valid, y_valid, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define a simple neural network model for ranking\n",
    "class RankNet(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RankNet, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x).squeeze()\n",
    "\n",
    "# ListNet loss function\n",
    "def listnet_loss(y_pred, y_true):\n",
    "    y_pred_softmax = torch.softmax(y_pred, dim=0)\n",
    "    y_true_softmax = torch.softmax(y_true, dim=0)\n",
    "    return -torch.sum(y_true_softmax * torch.log(y_pred_softmax))\n",
    "\n",
    "# ListMLE loss function\n",
    "def listmle_loss(y_pred, y_true):\n",
    "    _, sorted_indices = torch.sort(y_true, descending=True)\n",
    "    y_pred_sorted = y_pred[sorted_indices]\n",
    "    return -torch.sum(torch.log(torch.softmax(y_pred_sorted, dim=0)))\n",
    "\n",
    "# Train the model\n",
    "def train_model(model, loss_fn, X_train, y_train, X_valid, y_valid, lr=0.001, epochs=10, batch_size=128):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    train_dataset = torch.utils.data.TensorDataset(\n",
    "        torch.tensor(X_train, dtype=torch.float32),\n",
    "        torch.tensor(y_train, dtype=torch.float32)\n",
    "    )\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for X_batch, y_batch in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            y_pred = model(X_batch)\n",
    "            loss = loss_fn(y_pred, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {epoch_loss / len(train_loader):.4f}\")\n",
    "\n",
    "    # Evaluate on validation set\n",
    "    model.eval()\n",
    "    y_valid_pred = model(torch.tensor(X_valid, dtype=torch.float32)).detach().numpy()\n",
    "    ndcg = ndcg_score([y_valid], [y_valid_pred])\n",
    "    print(f\"Validation NDCG: {ndcg:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Main function\n",
    "if __name__ == \"__main__\":\n",
    "    # Prepare datasets\n",
    "    feature_count = 136  # Number of features in MSLR-WEB10K\n",
    "    X_train, y_train, X_valid, y_valid, X_test, y_test = prepare_datasets()\n",
    "\n",
    "    # Train ListNet\n",
    "    print(\"Training ListNet...\")\n",
    "    listnet_model = RankNet(input_dim=feature_count)\n",
    "    train_model(listnet_model, listnet_loss, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "    # Train ListMLE\n",
    "    print(\"Training ListMLE...\")\n",
    "    listmle_model = RankNet(input_dim=feature_count)\n",
    "    train_model(listmle_model, listmle_loss, X_train, y_train, X_valid, y_valid)\n",
    "\n",
    "    # Evaluate on test set\n",
    "    listnet_model.eval()\n",
    "    listmle_model.eval()\n",
    "    y_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    y_pred_listnet = listnet_model(y_test_tensor).detach().numpy()\n",
    "    y_pred_listmle = listmle_model(y_test_tensor).detach().numpy()\n",
    "\n",
    "    ndcg_listnet = ndcg_score([y_test], [y_pred_listnet])\n",
    "    ndcg_listmle = ndcg_score([y_test], [y_pred_listmle])\n",
    "\n",
    "    print(f\"Test NDCG (ListNet): {ndcg_listnet:.4f}\")\n",
    "    print(f\"Test NDCG (ListMLE): {ndcg_listmle:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
